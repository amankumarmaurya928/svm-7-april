{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2068549-db82-42a6-91b7-fdb6ceb5bc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models,\\n   that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables,\\n   allowing learning of non-linear models.\\n   the polynomial kernel looks not only at the given features of input samples to determine their similarity, but also \\n   combinations of these. In the context of regression analysis, such combinations are known as interaction features. \\n   The (implicit) feature space of a polynomial kernel is equivalent to that of polynomial regression, but without the \\n   combinatorial blowup in the number of parameters to be learned.\\n   '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''the polynomial kernel is a kernel function commonly used with support vector machines (SVMs) and other kernelized models,\n",
    "   that represents the similarity of vectors (training samples) in a feature space over polynomials of the original variables,\n",
    "   allowing learning of non-linear models.\n",
    "   the polynomial kernel looks not only at the given features of input samples to determine their similarity, but also \n",
    "   combinations of these. In the context of regression analysis, such combinations are known as interaction features. \n",
    "   The (implicit) feature space of a polynomial kernel is equivalent to that of polynomial regression, but without the \n",
    "   combinatorial blowup in the number of parameters to be learned.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab553551-4964-433b-a9b2-5515a92d05a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we implement an SVM with a polynomial kernel in Python using Scikit-learn:\\n\\nImporting the necessary libraries.\\nimport numpy as np.\\nfrom sklearn. datasets import load_digits.\\nfrom sklearn. model_selection import train_test_split.\\nfrom sklearn. svm import SVC.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''we implement an SVM with a polynomial kernel in Python using Scikit-learn:\n",
    "\n",
    "Importing the necessary libraries.\n",
    "import numpy as np.\n",
    "from sklearn. datasets import load_digits.\n",
    "from sklearn. model_selection import train_test_split.\n",
    "from sklearn. svm import SVC.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a782a372-5f31-4e28-957c-71f225661141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If epsilon is zero, we can expect overfitting\\n    Parameter ε controls the width of the ε-insensitive zone, used to fit the training data. The value of ε can affect the\\n    number of support vectors used to construct the regression function. The bigger ε, the fewer support vectors are selected.\\n    \\n    SVR has an additional tunable parameter ε (epsilon). The value of epsilon determines the width of the tube around the\\n    estimated function (hyperplane). Points that fall inside this tube are considered as correct predictions and are not\\n    penalized by the algorithm.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''If epsilon is zero, we can expect overfitting\n",
    "    Parameter ε controls the width of the ε-insensitive zone, used to fit the training data. The value of ε can affect the\n",
    "    number of support vectors used to construct the regression function. The bigger ε, the fewer support vectors are selected.\n",
    "    \n",
    "    SVR has an additional tunable parameter ε (epsilon). The value of epsilon determines the width of the tube around the\n",
    "    estimated function (hyperplane). Points that fall inside this tube are considered as correct predictions and are not\n",
    "    penalized by the algorithm.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5271b2b-de0a-41a3-8781-19a2bf86615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support \\n   vectors.\\n   The C parameter trades off correct classification of training examples against maximization of the decision function’s\\n   margin.\\n   '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support \n",
    "   vectors.\n",
    "   The C parameter trades off correct classification of training examples against maximization of the decision function’s\n",
    "   margin.\n",
    "   '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e0d1ff-995d-4d44-8e68-a1b89c6a6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5\n",
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_2d = X[:, :2]\n",
    "X_2d = X_2d[y > 0]\n",
    "y_2d = y[y > 0]\n",
    "y_2d -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d860c63-bdbe-48dc-b9c2-59eaef98eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_2d = scaler.fit_transform(X_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22db8b12-f923-4677-aa8f-e25aae04f428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1.0, 'gamma': 0.1} with a score of 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (grid.best_params_, grid.best_score_)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9145a887-a1c9-4379-891d-ff3601e09c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_2d_range = [1e-2, 1, 1e2]\n",
    "gamma_2d_range = [1e-1, 1, 1e1]\n",
    "classifiers = []\n",
    "for C in C_2d_range:\n",
    "    for gamma in gamma_2d_range:\n",
    "        clf = SVC(C=C, gamma=gamma)\n",
    "        clf.fit(X_2d, y_2d)\n",
    "        classifiers.append((C, gamma, clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116c8d6-3c94-4211-a035-261acbceb3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "xx, yy = np.meshgrid(np.linspace(-3, 3, 200), np.linspace(-3, 3, 200))\n",
    "for k, (C, gamma, clf) in enumerate(classifiers):\n",
    "    # evaluate decision function in a grid\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # visualize decision function for these parameters\n",
    "    plt.subplot(len(C_2d_range), len(gamma_2d_range), k + 1)\n",
    "    plt.title(\"gamma=10^%d, C=10^%d\" % (np.log10(gamma), np.log10(C)), size=\"medium\")\n",
    "\n",
    "    # visualize parameter's effect on decision function\n",
    "    plt.pcolormesh(xx, yy, -Z, cmap=plt.cm.RdBu)\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_2d, cmap=plt.cm.RdBu_r, edgecolors=\"k\")\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "scores = grid.cv_results_[\"mean_test_score\"].reshape(len(C_range), len(gamma_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addba06b-e682-4c3f-bf3d-fe7aa3b7e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=0.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(\n",
    "    scores,\n",
    "    interpolation=\"nearest\",\n",
    "    cmap=plt.cm.hot,\n",
    "    norm=MidpointNormalize(vmin=0.2, midpoint=0.92),\n",
    ")\n",
    "plt.xlabel(\"gamma\")\n",
    "plt.ylabel(\"C\")\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title(\"Validation accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d05a7-d515-421e-acfb-4a530b0c1943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcf09c8-3ab4-4677-a830-722fc63f1e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f906cac-4757-4739-bd6a-3b697015cf82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
